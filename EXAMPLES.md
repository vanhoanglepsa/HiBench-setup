# üìö V√≠ D·ª• Chi Ti·∫øt - HiBench Benchmarks

## üéØ M·ª•c L·ª•c

1. [WordCount - Text Processing](#1-wordcount---text-processing)
2. [TeraSort - Sorting](#2-terasort---sorting)
3. [PageRank - Graph Processing](#3-pagerank---graph-processing)
4. [K-Means - Machine Learning](#4-k-means---machine-learning)
5. [SQL Queries](#5-sql-queries)
6. [T√πy Ch·ªânh Config](#6-t√πy-ch·ªânh-config)

---

## 1. WordCount - Text Processing

### M√¥ t·∫£
ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói t·ª´ trong m·ªôt t·∫≠p d·ªØ li·ªáu text l·ªõn.

### Ch·∫°y Benchmark

```bash
# V√†o container
make shell-spark

# Trong container
cd /opt/hibench
cp /hibench/*.conf conf/

# Prepare data (t·∫°o ~500MB text data)
bin/workloads/micro/wordcount/prepare/prepare.sh

# Run Spark job
bin/workloads/micro/wordcount/spark/run.sh

# Xem k·∫øt qu·∫£
cat report/hibench.report
```

### Ki·ªÉm tra d·ªØ li·ªáu tr√™n HDFS

```bash
# Xem input data
hdfs dfs -ls /HiBench/Wordcount/Input

# Xem output
hdfs dfs -ls /HiBench/Wordcount/Output

# ƒê·ªçc m·ªôt ph·∫ßn output
hdfs dfs -cat /HiBench/Wordcount/Output/part-00000 | head -20
```

### T√πy ch·ªânh k√≠ch th∆∞·ªõc data

Ch·ªânh file `conf/hibench.conf`:

```properties
hibench.wordcount.datasize  1GB    # Thay ƒë·ªïi t·ª´ 500MB
```

---

## 2. TeraSort - Sorting

### M√¥ t·∫£
Sort m·ªôt l∆∞·ª£ng l·ªõn d·ªØ li·ªáu (100-byte records), benchmark ph·ªï bi·∫øn cho Hadoop/Spark.

### Ch·∫°y Benchmark

```bash
cd /opt/hibench

# Prepare (t·∫°o random data ƒë·ªÉ sort)
bin/workloads/micro/terasort/prepare/prepare.sh

# Run sort
bin/workloads/micro/terasort/spark/run.sh

# Verify output ƒë√£ sorted ch∆∞a
bin/workloads/micro/terasort/verify/verify.sh
```

### Scale l√™n

```bash
# Ch·ªânh trong conf/hibench.conf
hibench.terasort.datasize  5GB    # Thay ƒë·ªïi scale
```

---

## 3. PageRank - Graph Processing

### M√¥ t·∫£
T√≠nh PageRank score cho graph (m√¥ ph·ªèng web pages v√† links).

### Ch·∫°y Benchmark

```bash
cd /opt/hibench

# Prepare graph data
bin/workloads/websearch/pagerank/prepare/prepare.sh

# Run PageRank (3 iterations)
bin/workloads/websearch/pagerank/spark/run.sh
```

### T√πy ch·ªânh

```properties
# conf/hibench.conf
hibench.pagerank.pages          100000  # S·ªë l∆∞·ª£ng pages
hibench.pagerank.numiterations  5       # S·ªë iterations
```

### Xem output

```bash
hdfs dfs -ls /HiBench/Pagerank/Output
hdfs dfs -cat /HiBench/Pagerank/Output/part-00000 | head -10
```

---

## 4. K-Means - Machine Learning

### M√¥ t·∫£
Clustering algorithm, ph√¢n lo·∫°i data points th√†nh K clusters.

### Ch·∫°y Benchmark

```bash
cd /opt/hibench

# Prepare training data
bin/workloads/ml/kmeans/prepare/prepare.sh

# Run K-Means clustering
bin/workloads/ml/kmeans/spark/run.sh
```

### T√πy ch·ªânh

```properties
# conf/hibench.conf
hibench.kmeans.num_of_clusters     5      # S·ªë clusters
hibench.kmeans.num_of_samples      10000000  # S·ªë samples
hibench.kmeans.dimensions          20     # S·ªë dimensions
hibench.kmeans.max_iteration       10     # Max iterations
```

### Xem model output

```bash
hdfs dfs -ls /HiBench/Kmeans/Output
hdfs dfs -cat /HiBench/Kmeans/Output/part-00000 | head
```

---

## 5. SQL Queries

### Scan Query

```bash
cd /opt/hibench

# Prepare table data
bin/workloads/sql/scan/prepare/prepare.sh

# Run SQL scan query
bin/workloads/sql/scan/spark/run.sh
```

### Join Query

```bash
# Prepare
bin/workloads/sql/join/prepare/prepare.sh

# Run
bin/workloads/sql/join/spark/run.sh
```

### Aggregation Query

```bash
# Prepare
bin/workloads/sql/aggregation/prepare/prepare.sh

# Run
bin/workloads/sql/aggregation/spark/run.sh
```

---

## 6. T√πy Ch·ªânh Config

### Thay ƒë·ªïi Scale Profile

File: `conf/hibench.conf`

```properties
# Options: tiny, small, large, huge, gigantic, bigdata
hibench.scale.profile   large

# Ho·∫∑c t√πy ch·ªânh t·ª´ng workload:
hibench.wordcount.datasize    5GB
hibench.sort.datasize         10GB
hibench.terasort.datasize     20GB
```

### T√πy ch·ªânh Spark Resources

File: `conf/spark.conf`

```properties
# TƒÉng memory
spark.executor.memory           4g
spark.driver.memory             2g

# TƒÉng cores
spark.executor.cores            4

# TƒÉng s·ªë executors
spark.executor.instances        2
```

### T√πy ch·ªânh HDFS

File: `conf/hadoop.conf`

```properties
# TƒÉng replication (n·∫øu c√≥ nhi·ªÅu datanodes)
hibench.hdfs.replication        2

# Thay ƒë·ªïi block size
hibench.default.hdfs.block.size    268435456  # 256MB
```

---

## üìä So S√°nh K·∫øt Qu·∫£

### Xem Report

```bash
# Xem t·∫•t c·∫£ k·∫øt qu·∫£
cat /opt/hibench/report/hibench.report

# Xem d·∫°ng table
column -t -s $'\t' /opt/hibench/report/hibench.report

# Export sang local
docker cp spark-master:/opt/hibench/report/hibench.report ./results.txt
```

### Format Report

Report bao g·ªìm c√°c c·ªôt:
- **Type**: Workload type (micro, websearch, ml, sql)
- **Date**: Th·ªùi gian ch·∫°y
- **Time**: T·ªïng th·ªùi gian (seconds)
- **Input**: K√≠ch th∆∞·ªõc input data
- **Output**: K√≠ch th∆∞·ªõc output data
- **Throughput**: MB/s

---

## üîß Debug & Troubleshooting

### Xem Spark UI trong khi ch·∫°y

M·ªü browser: http://localhost:4040

### Xem logs chi ti·∫øt

```bash
# Trong container
tail -f /opt/spark/logs/*.out

# Ho·∫∑c t·ª´ host
docker logs -f spark-master
```

### Memory issues

N·∫øu g·∫∑p OOM (Out of Memory):

```properties
# Gi·∫£m scale
hibench.scale.profile   tiny

# Ho·∫∑c gi·∫£m memory footprint
spark.memory.fraction   0.6
spark.memory.storageFraction   0.3
```

### HDFS space issues

```bash
# X√≥a d·ªØ li·ªáu c≈©
hdfs dfs -rm -r /HiBench/Wordcount
hdfs dfs -rm -r /HiBench/Terasort

# Ho·∫∑c x√≥a t·∫•t c·∫£
make hdfs-clean
```

---

## üöÄ Ch·∫°y Multiple Benchmarks

### Script t·ª± ƒë·ªông

T·∫°o file `run_all_benchmarks.sh`:

```bash
#!/bin/bash

cd /opt/hibench
cp /hibench/*.conf conf/

BENCHMARKS=(
    "micro/wordcount"
    "micro/sort"
    "micro/terasort"
    "websearch/pagerank"
    "ml/kmeans"
)

for bench in "${BENCHMARKS[@]}"; do
    echo "Running $bench..."
    bin/workloads/$bench/prepare/prepare.sh
    bin/workloads/$bench/spark/run.sh
done

echo "All benchmarks completed!"
cat report/hibench.report
```

Ch·∫°y:

```bash
docker exec -it spark-master bash run_all_benchmarks.sh
```

---

## üìà Performance Tuning Tips

### 1. Optimize Parallelism

```properties
hibench.default.map.parallelism     4
hibench.default.shuffle.parallelism 4
```

### 2. Adjust Spark Configuration

```properties
spark.default.parallelism          8
spark.sql.shuffle.partitions       8
```

### 3. Enable Compression

```properties
spark.shuffle.compress              true
spark.io.compression.codec          snappy
```

### 4. Tune Memory

```properties
spark.executor.memory               4g
spark.driver.memory                 2g
spark.memory.fraction               0.6
```

---

**Happy Benchmarking! üéØ**

