# Makefile cho HiBench Hadoop & Spark Setup
# Sá»­ dá»¥ng: make <command>

.PHONY: help setup start stop restart status logs clean check build shell-spark shell-hadoop test

# Default target
help:
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "  HiBench Hadoop & Spark Docker Setup"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo ""
	@echo "ğŸ“¦ Setup Commands:"
	@echo "  make setup        - Khá»Ÿi táº¡o vÃ  start toÃ n bá»™ (láº§n Ä‘áº§u)"
	@echo "  make start        - Start cÃ¡c containers"
	@echo "  make stop         - Stop cÃ¡c containers"
	@echo "  make restart      - Restart táº¥t cáº£"
	@echo "  make clean        - Dá»«ng vÃ  xÃ³a háº¿t (bao gá»“m volumes)"
	@echo ""
	@echo "ğŸ“Š Monitoring:"
	@echo "  make status       - Xem tráº¡ng thÃ¡i containers"
	@echo "  make logs         - Xem logs cá»§a táº¥t cáº£ services"
	@echo "  make check        - Kiá»ƒm tra health cá»§a services"
	@echo ""
	@echo "ğŸ”§ Development:"
	@echo "  make shell-spark  - VÃ o shell cá»§a Spark Master"
	@echo "  make shell-hadoop - VÃ o shell cá»§a Hadoop NameNode"
	@echo "  make test         - Cháº¡y test benchmark (WordCount)"
	@echo ""
	@echo "ğŸŒ Web UIs:"
	@echo "  - Hadoop:  http://localhost:9870"
	@echo "  - Spark:   http://localhost:8080"
	@echo "  - Worker:  http://localhost:8081"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Kiá»ƒm tra Docker cÃ³ cháº¡y khÃ´ng
check:
	@echo "ğŸ” Kiá»ƒm tra Docker..."
	@docker info > /dev/null 2>&1 || (echo "âŒ Docker chÆ°a cháº¡y!" && exit 1)
	@echo "âœ… Docker OK"
	@echo ""
	@echo "ğŸ” Kiá»ƒm tra Docker Compose..."
	@which docker-compose > /dev/null || (echo "âŒ Docker Compose chÆ°a cÃ i!" && exit 1)
	@echo "âœ… Docker Compose OK"

# Setup ban Ä‘áº§u (build + start + init)
setup: check
	@echo "ğŸš€ Báº¯t Ä‘áº§u setup HiBench environment..."
	@./scripts/setup.sh

# Build images (náº¿u cáº§n)
build:
	@echo "ğŸ”¨ Building Docker images..."
	docker-compose build

# Start containers
start: check
	@echo "â–¶ï¸  Starting containers..."
	docker-compose up -d
	@echo "âœ… Containers started!"
	@echo ""
	@make status

# Stop containers
stop:
	@echo "â¹ï¸  Stopping containers..."
	@./scripts/stop.sh

# Restart táº¥t cáº£
restart:
	@echo "ğŸ”„ Restarting all services..."
	docker-compose restart
	@echo "âœ… Services restarted!"

# Xem status
status:
	@./scripts/status.sh

# Xem logs
logs:
	docker-compose logs -f

# Logs cá»§a tá»«ng service
logs-spark:
	docker-compose logs -f spark-master

logs-hadoop:
	docker-compose logs -f namenode

logs-worker:
	docker-compose logs -f spark-worker

# VÃ o shell cá»§a Spark Master
shell-spark:
	@echo "ğŸš Connecting to Spark Master shell..."
	@echo "Tip: HiBench directory: /opt/hibench"
	@echo "Tip: Config files: /hibench/"
	docker exec -it spark-master bash

# VÃ o shell cá»§a Hadoop NameNode
shell-hadoop:
	@echo "ğŸš Connecting to Hadoop NameNode shell..."
	docker exec -it namenode bash

# Clean up (xÃ³a háº¿t bao gá»“m volumes)
clean:
	@echo "ğŸ§¹ Cleaning up everything..."
	@read -p "âš ï¸  XÃ³a táº¥t cáº£ bao gá»“m dá»¯ liá»‡u HDFS? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		docker-compose down -v; \
		echo "âœ… Cleaned!"; \
	else \
		echo "âŒ Cancelled"; \
	fi

# Test vá»›i WordCount benchmark
test:
	@echo "ğŸ§ª Running WordCount benchmark test..."
	docker exec -it spark-master bash -c "cd /opt/hibench && \
		cp /hibench/*.conf conf/ && \
		bin/workloads/micro/wordcount/prepare/prepare.sh && \
		bin/workloads/micro/wordcount/spark/run.sh && \
		cat report/hibench.report"

# Quick test (chá»‰ check connectivity)
test-quick:
	@echo "âš¡ Quick connectivity test..."
	@echo "Testing HDFS..."
	docker exec namenode hdfs dfs -ls /
	@echo ""
	@echo "Testing Spark..."
	docker exec spark-master spark-submit --version

# Init HDFS directories
init-hdfs:
	@echo "ğŸ“ Initializing HDFS directories..."
	docker exec namenode bash -c "\
		hdfs dfs -mkdir -p /HiBench && \
		hdfs dfs -mkdir -p /spark-logs && \
		hdfs dfs -mkdir -p /user/root && \
		hdfs dfs -chmod -R 777 /HiBench && \
		hdfs dfs -chmod -R 777 /spark-logs && \
		hdfs dfs -chmod -R 777 /user"
	@echo "âœ… HDFS initialized!"

# Xem HDFS
hdfs-ls:
	docker exec namenode hdfs dfs -ls /

# HDFS report
hdfs-report:
	docker exec namenode hdfs dfsadmin -report

# Clean HDFS data (giá»¯ containers)
hdfs-clean:
	@echo "ğŸ—‘ï¸  Cleaning HiBench data on HDFS..."
	docker exec namenode hdfs dfs -rm -r -f /HiBench/* || true
	@echo "âœ… HDFS cleaned!"

