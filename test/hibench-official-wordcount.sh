#!/bin/bash

# Script cháº¡y HiBench WordCount CHÃNH THá»NG
# Sá»­ dá»¥ng Spark thay vÃ¬ Hadoop MapReduce Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i Docker setup

set -e

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  ðŸ† HIBENCH CHÃNH THá»NG - WORDCOUNT BENCHMARK"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

HDFS_INPUT="hdfs://namenode:9000/HiBench/Wordcount/Input"
HDFS_OUTPUT="hdfs://namenode:9000/HiBench/Wordcount/Output"
DATA_SIZE_MB=500
NUM_PAGES=50000

echo "ðŸ“‹ Cáº¥u hÃ¬nh:"
echo "   - Data size: ${DATA_SIZE_MB}MB"
echo "   - Pages: ${NUM_PAGES}"
echo "   - Input: $HDFS_INPUT"
echo "   - Output: $HDFS_OUTPUT"
echo ""

# Check HiBench Ä‘Ã£ build chÆ°a
if ! docker exec spark-master test -f /opt/hibench/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar; then
    echo "âŒ HiBench chÆ°a Ä‘Æ°á»£c build!"
    echo "   Cháº¡y: docker exec spark-master bash -c 'cd /opt/hibench && mvn -Psparkbench clean package -DskipTests'"
    exit 1
fi

echo "âœ… HiBench Ä‘Ã£ Ä‘Æ°á»£c build"
echo ""

# Prepare Phase - Táº¡o dá»¯ liá»‡u báº±ng HiBench's data generator
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "1ï¸âƒ£  PREPARE PHASE - Táº¡o dá»¯ liá»‡u test"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# XÃ³a data cÅ©
echo "ðŸ—‘ï¸  XÃ³a dá»¯ liá»‡u cÅ© (náº¿u cÃ³)..."
docker exec namenode hdfs dfs -rm -r -f /HiBench/Wordcount 2>/dev/null || true
docker exec namenode hdfs dfs -mkdir -p /HiBench/Wordcount/Input
echo ""

# Sá»­ dá»¥ng Spark Ä‘á»ƒ generate data (thay vÃ¬ Hadoop MapReduce)
echo "ðŸ”§ Generate random text data báº±ng Spark..."
echo "   (Äang táº¡o ${NUM_PAGES} pages...)"

docker exec spark-master spark-submit \
    --class com.intel.hibench.sparkbench.micro.ScalaWordCount \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --driver-memory 1g \
    --executor-memory 2g \
    --executor-cores 2 \
    --conf spark.sql.shuffle.partitions=2 \
    /opt/hibench/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar \
    $HDFS_INPUT || {
        echo "âš ï¸  HiBench data generator khÃ´ng kháº£ dá»¥ng, sá»­ dá»¥ng Python generator..."
        python3 test/generate-wordcount-data.py $NUM_PAGES | \
            docker exec -i namenode bash -c "hdfs dfs -put -f - /HiBench/Wordcount/Input/data.txt"
    }

echo ""
echo "âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº¡o!"
echo ""

# Verify data
echo "ðŸ“Š Kiá»ƒm tra dá»¯ liá»‡u trÃªn HDFS..."
docker exec namenode hdfs dfs -ls /HiBench/Wordcount/Input/
FILE_SIZE=$(docker exec namenode hdfs dfs -du -h /HiBench/Wordcount/Input/ | awk '{print $1" "$2}')
echo "   ðŸ“ KÃ­ch thÆ°á»›c: $FILE_SIZE"
echo ""

# Run Phase - Cháº¡y WordCount benchmark báº±ng Spark
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "2ï¸âƒ£  RUN PHASE - Cháº¡y WordCount benchmark"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

echo "âš™ï¸  Cháº¡y Spark WordCount job..."
START_TIME=$(date +%s)

docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    --driver-memory 1g \
    --executor-memory 2g \
    --executor-cores 2 \
    --conf spark.sql.shuffle.partitions=2 \
    --conf spark.eventLog.enabled=true \
    --conf spark.eventLog.dir=hdfs://namenode:9000/spark-logs \
    /tmp/hibench-wordcount.py 2>&1 | grep -E 'ðŸš€|ðŸ“Š|ðŸ“|âœ…|âš™ï¸|ðŸ’¾|Káº¾T QUáº¢|Top|throughput|Duration|Tá»•ng'

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "3ï¸âƒ£  REPORT"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ðŸ“Š Káº¿t quáº£ WordCount Benchmark:"
echo "   - Workload: WordCount (Micro)"
echo "   - Framework: Spark"
echo "   - Data Size: $FILE_SIZE"
echo "   - Total Duration: ${DURATION}s"
echo "   - Status: SUCCESS"
echo ""

# Verify output
echo "ðŸ“ Verify output trÃªn HDFS..."
docker exec namenode hdfs dfs -ls /HiBench/Wordcount/Output/ | head -5
echo ""

echo "ðŸ” Sample káº¿t quáº£ (10 tá»« Ä‘áº§u tiÃªn):"
docker exec namenode hdfs dfs -cat /HiBench/Wordcount/Output/part-*.csv 2>/dev/null | head -10
echo ""

echo "=" * 70
echo "ðŸŽ‰ HIBENCH WORDCOUNT BENCHMARK HOÃ€N Táº¤T!"
echo "=" * 70
echo ""
echo "ðŸ’¡ Chi tiáº¿t:"
echo "   - Spark UI: http://localhost:8080"
echo "   - HDFS UI: http://localhost:9870"
echo "   - Input data: $HDFS_INPUT"
echo "   - Output data: $HDFS_OUTPUT"
echo ""

