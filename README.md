# HiBench - Hadoop & Spark Benchmark Suite

Docker environment for running HiBench benchmarks with Hadoop HDFS and Apache Spark.

## ğŸš€ Quick Start

```bash
# Initial setup (build containers, init HDFS, build HiBench)
make setup

# Start containers
make start

#check-job
make check-job  

# Run WordCount benchmark test
make test
```

## ğŸ“‹ Main Commands

### Container Management

```bash
make start        # Start containers
make stop         # Stop containers
make status       # View status
make logs         # View logs
make clean        # Remove everything (including data)
```

### Development

```bash
make shell-spark   # Enter Spark Master container
make shell-hadoop  # Enter Hadoop NameNode container
make test          # Test WordCount benchmark
```

## ğŸ† Run Benchmarks

### MICRO Benchmarks

```bash
make wordcount     # WordCount
make sort          # Sort
make terasort      # TeraSort
make repartition   # Repartition
make dfsioe-read   # DFSIOE Read
make dfsioe-write  # DFSIOE Write
```

### MACHINE LEARNING

```bash
make kmeans        # K-Means
make bayes         # Naive Bayes
make lr            # Logistic Regression
make svm           # SVM
make als           # ALS
make rf            # Random Forest
make gbt           # Gradient Boosted Trees
make linear        # Linear Regression
make gmm           # Gaussian Mixture Model
make lda           # LDA
make pca           # PCA
make xgboost       # XGBoost
make svd           # SVD
```

### SQL

```bash
make scan          # Scan
make join          # Join
make aggregation   # Aggregation
```

### WEB SEARCH

```bash
make pagerank      # PageRank
make nutchindexing # Nutch Indexing
```

### GRAPH

```bash
make nweight       # N-Weight
```

### STREAMING

```bash
make identity              # Identity
make repartition-streaming # Repartition Streaming
make wordcount-streaming   # WordCount Streaming
```

## ğŸŒ Web UIs

- **Hadoop NameNode**: http://localhost:9870
- **Spark Master**: http://localhost:8080
- **Spark Worker**: http://localhost:8081

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Network                  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ NameNode â”‚â—„â”€â”€â”€â”€â–ºâ”‚ DataNode â”‚       â”‚
â”‚  â”‚  :9000   â”‚      â”‚  (HDFS)  â”‚       â”‚
â”‚  â”‚  :9870   â”‚      â”‚          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                                 â”‚
â”‚       â”‚ HDFS                            â”‚
â”‚       â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Spark   â”‚â—„â”€â”€â”€â”€â–ºâ”‚  Spark   â”‚       â”‚
â”‚  â”‚  Master  â”‚      â”‚  Worker  â”‚       â”‚
â”‚  â”‚  :7077   â”‚      â”‚  :8081  â”‚       â”‚
â”‚  â”‚  :8080   â”‚      â”‚          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Set-up/
â”œâ”€â”€ docker-compose.yml      # Container definitions
â”œâ”€â”€ Dockerfile.spark        # Spark image with Hadoop client
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ hadoop/            # Hadoop configs
â”‚   â””â”€â”€ spark/             # Spark configs
â”œâ”€â”€ hibench-workspace/     # HiBench configs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh          # Setup script
â”‚   â””â”€â”€ run-hibench-workload.sh  # Workload runner
â””â”€â”€ Makefile              # All commands
```

## ğŸ”§ Troubleshooting

```bash
# View logs
make logs

# Restart containers
make restart

# Full reset
make clean
make setup

# Check HDFS
make hdfs-ls
make hdfs-report
```

## ğŸ“ Notes

- All benchmarks automatically run prepare phase (if available)
- Results are saved in `/opt/hibench/report/` inside container
- HDFS data is stored in Docker volumes
- View all commands: `make help`
