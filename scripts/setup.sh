#!/bin/bash

# Script to setup HiBench environment with Hadoop and Spark

set -e

echo "ğŸš€ Starting HiBench environment setup..."
echo ""

# Check Docker
echo "ğŸ³ Checking Docker..."
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker is not installed. Please install Docker Desktop."
    exit 1
fi

if ! docker info &> /dev/null; then
    echo "âŒ Docker daemon is not running. Please start Docker Desktop."
    exit 1
fi

echo "âœ… Docker is ready"
echo ""

# Check Docker Compose
echo "ğŸ”§ Checking Docker Compose..."
if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose is not installed."
    exit 1
fi

echo "âœ… Docker Compose is ready"
echo ""

# Build and start containers
echo "ğŸ”¨ Building and starting containers..."
docker-compose up -d

echo ""
echo "â³ Waiting for services to start (60 seconds)..."
sleep 60

# Initialize HDFS
echo ""
echo "ğŸ“ Initializing HDFS..."
docker exec -it namenode bash -c "
    hdfs dfs -mkdir -p /HiBench
    hdfs dfs -mkdir -p /spark-logs
    hdfs dfs -mkdir -p /user/root
    hdfs dfs -chmod -R 777 /HiBench
    hdfs dfs -chmod -R 777 /spark-logs
    hdfs dfs -chmod -R 777 /user
"

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ğŸ“Š Web UIs available:"
echo "  - Hadoop NameNode: http://localhost:9870"
echo "  - Spark Master:     http://localhost:8080"
echo "  - Spark Worker:     http://localhost:8081"
echo "  - Spark App UI:     http://localhost:4040 (when running jobs)"
echo ""
echo "ğŸ“ To run HiBench benchmark, use:"
echo "   docker exec -it spark-master bash"
echo "   cd /hibench"
echo ""

